{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Scikit-Learn (sklearn)\n","\n","- Most popular for classical machine learning (not deep learning)\n","- Interface for Support Vector Machine, Decision Tree, Random Forest, ...\n","- Build on top of NumPy and SciPy\n","\n","Here is the code which loads and splits an example dataset (Iris, very clean dataset) and trains a classical machine learning algorithm (SVC) on it:\n","\n","```python\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score\n","\n","# Load the Iris dataset\n","iris = load_iris()\n","X, y = iris.data, iris.target\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Choose a classifier (Support Vector Classifier)\n","clf = SVC()\n","\n","# Train the model\n","clf.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = clf.predict(X_test)\n","\n","# Evaluate the model's accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","```\n","\n","Comparing this code with the first code snippet in \"8_Fastai\", we see a lot of similarities. So lets map the concepts we just learned in \"8_Fastai\" to this code snippet to understand what it is doing.\n"],"metadata":{"id":"YKE4ZyPgV7Cx"}},{"cell_type":"markdown","source":["\n","## 1. Load Data\n","**sklearn**\n","```python\n","# Load the Iris dataset\n","iris = load_iris()\n","X, y = iris.data, iris.target\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","```\n","**fastai**\n","```python\n","# Load data\n","dls = TabularDataLoaders.from_csv('sample_data/titanic.csv',\n","                                  y_names=['Survived'],\n","                                  y_block = CategoryBlock,\n","                                  cat_names=['Pclass', 'Sex', 'Embarked'],\n","                                  cont_names=['Age', 'Fare', 'SibSp'],\n","                                  procs=[Categorify, FillMissing, Normalize])\n","```\n","\n","Data loading in sklearn is directly done on DataFrames/NumPy arrays (`iris` is a DataFrame and `X`, `y` are NumPy arrays) instead of using a `DataLoaders` class which does the same (+preprocessing) under the hood. The sklearn code does\n","1. Load the DataFrame\n","2. Splits the DataFrame into the features X and the target y\n","3. Splits both DataFrames into train and test arrays\n","\n","For sklearn, any needed preprocessing (fill missing values, categorify, normalize) has to be done \"by hand\" on the DataFrames/arrays. We will not go into much detail regarding preprocessing since photonai (our in-house framework build on top of sklearn) handles preprocessing (see 10_Photon).\n"],"metadata":{"id":"pEnXkwZlrwo-"}},{"cell_type":"markdown","source":["\n","## 2. Load Model\n","**sklearn**\n","```python\n","clf = SVC()\n","```\n","**fastai**\n","```python\n","learn = tabular_learner(dls, metrics=[accuracy])\n","```\n","\n","In sklearn you choose between classical ML model classes\n","- Support Vector Classifier `sklearn.svm.SVC` or Regressor `sklearn.svm.SVR`\n","- Decision Tree Classifier `sklearn.tree.DecisionTreeClassifier` or Regressor `sklearn.tree.DecisionTreeRegressor`\n","- Random Forest Classifier `sklearn.ensemble.RandomForestClassifier` or Regressor `sklearn.ensemble.RandomForestRegressor`\n","- Gaussian Process Classifier `sklearn.gaussian_process.GaussianProcessClassifier` or Regressor `sklearn.gaussian_process.GaussianProcessRegressor`\n","- ...\n","\n","instead of PyTorch models - i.e. neural network - which are used in fastai.\n","\n","Each ML model class comes with different hyperparameters (e.g. SVM -> C, gamma; DecisionTree -> max_depth, min_samples_split, ...) which govern the internal settings of the respective model. Changing these hyperparameters to maximize model performance (in the test data) is called **hyperparameter optimization**.\n","\n","We will not go into the details of how to choose models and hyperparameters. Again we refer to photonai which enables you to easily run experiments across many sklearn models and hyperparameters with proper validation on your data, such that you can simply pick the best performing model/hyperparameter (see 10_Photon).\n"],"metadata":{"id":"vKihgva4ryxO"}},{"cell_type":"markdown","source":["\n","## 3. Model training\n","**sklearn**\n","```python\n","clf.fit(X_train, y_train)\n","```\n","**fastai**\n","```python\n","learn.fit_one_cycle(5)\n","```\n","\n","In sklearn you directly pass the features `X` and `y` to the `fit` method of the ML model instance you defined.\n","\n","In contrast to neural network, training duration (e.g. epochs) is not a general hyperparameter for classical ML models."],"metadata":{"id":"7cSf38EYr2xF"}},{"cell_type":"markdown","source":["## 4. Evaluation\n","**sklearn**\n","```python\n","y_pred = clf.predict(X_test)\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","```\n","**fastai**\n","```python\n","interp = ClassificationInterpretation.from_learner(learn)\n","interp.plot_confusion_matrix()\n","```\n","\n","In sklearn you directly pass the features `X` to the `predict` method of the fitted ML model to get predictions.\n","\n","By calculating the accuracy of these predictions `y_pred` with respect to the targets `y_test` we can evaluate the model performance of the test data.\n","\n","**Task:** Copy and paste the whole analysis code and add lines which plot a confusion matrix based on `y_pred` and `y_test`.\n"],"metadata":{"id":"WEk82sEot8Ip"}},{"cell_type":"markdown","source":["\n","Hint: `from sklearn.metrics import confusion_matrix`"],"metadata":{"id":"L4OwNZj9D8oy"}},{"cell_type":"code","source":[],"metadata":{"id":"hDuv2c_BPtod"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Cross Validation\n","Cross Validation is an **alternative to splitting** your data in a **training** and a **test** set **once** for validation.\n","\n","![](https://miro.medium.com/v2/resize:fit:1200/1*AAwIlHM8TpAVe4l2FihNUQ.png)\n","\n","In 5-fold cross validation the **training and subsequent testing is repeated 5 times** each time using another 20% of the total data for testing.\n","\n","*Pros*\n","\n","- **Use all data** for training (and testing)\n","- More validation -> Overfitting (via manual optimization) less likely\n","\n","*Cons*\n","\n","- **Longer runtime** (5-fold CV -> 5x runtime)\n","\n","So the only cases in which it can be reasonable to rely on a simple train-test split instead of cross validation is if you work with\n","\n","- large datasets\n","- limited compute\n","- models with long training time\n","\n","\n"," and/or if you are at an early stage of your analysis where you quickly explore if certain models work at all.\n","\n"," By using `KFold` instead of `train_test_split` you can apply cross validation in your analysis.\n","\n"," **Task:** Given `X = np.random.random((30, 7))` use [`KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) to generate a list containing 5 numpy arrays which each contain the test indizes of the respective fold. How can you avoid that the test indizes are different each time you rerun the code?"],"metadata":{"id":"KOymfunOZhgL"}},{"cell_type":"code","source":[],"metadata":{"id":"B-FUw7N9PxCk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","## Exercise\n","Modify the given analysis code such that a 5-fold cross validation is applied and calculate the mean accuracy across all 5 test sets."],"metadata":{"id":"v04hDdSVAUg_"}},{"cell_type":"code","source":[],"metadata":{"id":"h3nfRIIYP0eM"},"execution_count":null,"outputs":[]}]}